# RFP Scraper

**Modular, scalable Python RFP Scraper** for 50+ U.S. state procurement portalsâ€”plug-and-play scraper classes with Excel export.
*Tags:* `rfp` `procurement` `scraper` `selenium` `requests` `excel`

---

## ğŸ” Why?

Manually monitoring 20+ keywords across 50+ state procurement websites is a huge time sink.
**RFP Scraper** centralizes all RFP postings into a single `.xlsx` fileâ€”so you never miss a bid.

---

## ğŸš€ Features

* ğŸ”Œ Modular core with base classes for `requests`- and `Selenium`-powered scrapers
* âœ… Out-of-the-box support for:

  * Alabama
  * Arizona
  * Arkansas
  * California
  * Colorado
  * Connecticut
  * (More Coming)
* ğŸ—‚ï¸ Keyword list (`keywords.txt`): one keyword per line
* âš™ï¸ Simple settings link-up for new scrapers (add URL or endpoint in `settings.py`)
* ğŸ“Š Excel export (`.xlsx`) with:

  * âœ“ Header formatting, autofilter, checkboxes, and conditional formatting
  * âœ“ Logo insertion
* ğŸ“ Smoke test (`smoke_test.py`) to verify each scraper runs without crashing
* ğŸ“ˆ Scales easily to all 50 states by dropping in new scraper files
* ğŸ“ Basic logging to `output/scraper.log` (INFO + ERROR)

---

## ğŸ“‚ Repo Layout

```
.  
â”œâ”€â”€ assets/  
â”‚   â””â”€â”€ hotb_logo.jpg  
â”‚   â””â”€â”€ output_example.png      # sample Excel screenshot  
â”œâ”€â”€ output/  
â”‚   â”œâ”€â”€ rfp_scraping_output.xlsx  
â”‚   â””â”€â”€ scraper.log  
â”œâ”€â”€ scraper/  
â”‚   â”œâ”€â”€ config/  
â”‚   â”‚   â”œâ”€â”€ keywords.txt        # one keyword per line  
â”‚   â”‚   â””â”€â”€ settings.py         # STATE_RFP_URL_MAP, BUSINESS_UNIT_DICT, etc.  
â”‚   â”œâ”€â”€ core/  
â”‚   â”‚   â”œâ”€â”€ base_scraper.py     # (if applicable)  
â”‚   â”‚   â”œâ”€â”€ requests_scraper.py  
â”‚   â”‚   â””â”€â”€ selenium_scraper.py  
â”‚   â”œâ”€â”€ exporters/  
â”‚   â”‚   â””â”€â”€ excel_exporter.py   # builds formatted `.xlsx`  
â”‚   â”œâ”€â”€ scrapers/  
â”‚   â”‚   â”œâ”€â”€ alabama.py  
â”‚   â”‚   â”œâ”€â”€ arizona.py  
â”‚   â”‚   â”œâ”€â”€ arkansas.py  
â”‚   â”‚   â”œâ”€â”€ california.py  
â”‚   â”‚   â”œâ”€â”€ colorado.py  
â”‚   â”‚   â””â”€â”€ connecticut.py  
â”‚   â”œâ”€â”€ tests/                  # (future) unit tests for core & scrapers  
â”‚   â””â”€â”€ utils/  
â”‚       â”œâ”€â”€ data_utils.py       # filter_by_keywords, etc.  
â”‚       â”œâ”€â”€ date_utils.py       # convert_to_pst, etc.  
â”‚       â””â”€â”€ text_utils.py       # (if needed)   
â”œâ”€â”€ main.py                     # entry point: parse args, run selected scrapers, call Excel exporter  
â”œâ”€â”€ LICENSE  
â”œâ”€â”€ README.md  
â””â”€â”€ requirements.txt  
```

---

## âš™ï¸ Installation

```bash
git clone https://github.com/jasonstaker/rfp-scraper.git
cd rfp-scraper
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

Requires Python 3.x (tested on 3.13.3).

---

## ğŸ“– Usage

```bash
# Run all supported states:
python main.py --states all

# Or target specific states (space-separated lowercase names):
python main.py --states alabama colorado california
```

* `--states all` runs every scraper in `scraper/scrapers/`
* `--states <nameâ€¦>` for individual or multiple states
* Outputs:

  * `output/rfp_scraping_output.xlsx`
  * `output/scraper.log`

### Smoke Test

```bash
python smoke_test.py
```

Exits with code 0 if every scraperâ€™s `scrape()` returned a `list` without unhandled exceptions; otherwise exits 1 and prints which state(s) failed.

---

## ğŸ› ï¸ Configuration

* **Keywords**

  * File: `scraper/config/keywords.txt`
  * Add one keyword per line (case-insensitive). Any RFP whose title or description contains at least one keyword will be tagged.

* **Settings**

  * File: `scraper/config/settings.py`
  * Contains:

    * `STATE_RFP_URL_MAP` â†’ state-to-URL mapping
    * `BUSINESS_UNIT_DICT` â†’ used by the California scraper
    * Other constants (e.g. `FALLBACK_CSRF`)
  * To add a new scraper:

    1. Add its base URL (or endpoint) under `STATE_RFP_URL_MAP["<state>"]`.
    2. If applicable (California), add departmentâ†’BU mapping in `BUSINESS_UNIT_DICT`.

* **Logging**

  * Configured in `scraper/logging_config.py` (if present) or via `logging.basicConfig` in `main.py`.
  * Output written to `output/scraper.log` at INFO + ERROR levels.

---

## â• Adding a New State

1. Create a new file in `scraper/scrapers/`, e.g. `illinois.py`.
2. Subclass one of the base scrapers in `scraper/core/`:

   * `RequestsScraper` for static HTML or JSON endpoints
   * `SeleniumScraper` for dynamic/JS-driven pages
3. Implement:

   * `search(self, **kwargs)` â†’ return page source or JSON
   * `extract_data(self, page_source)` â†’ parse and return `List[Dict]` of raw records
   * (Optional) pagination via `next_page()`
   * `scrape(self, **kwargs)` â†’ orchestrate `search()`, `extract_data()`, pagination, DataFrame, filter, return `List[Dict]`
4. Add entry into `STATE_RFP_URL_MAP` in `settings.py`.
5. Run it with:

   ```bash
   python main.py --states illinois
   ```

---

## âœ… Testing (Early Dev)

*Currently no official unit tests.*
For now, run:

```bash
python smoke_test.py
```

to verify that all built-in scrapers complete without uncaught exceptions.
We plan to add `pytest` tests for:

* Core scraper base classes
* Utility functions (`data_utils`, `date_utils`)
* Individual scraper logic (mocked HTML/JSON)

---

## ğŸ“¦ Output Columns

The exported `.xlsx` file (â€œAll RFPsâ€ sheet) includes:

|   | Proposal title | State      | Solicitation # | Due Date           | Keyword Hits | Link      |
| - | -------------- | ---------- | -------------- | ------------------ | ------------ | --------- |
|   | **(checkbox)** | **(auto)** | **(auto)**     | **(UTC-7) string** | **(auto)**   | **(URL)** |

1. **First column** is a clickable checkbox for â€œselected.â€
2. **Proposal title** â†’ from each scraperâ€™s `Label`.
3. **State** â†’ capitalized state name (e.g., â€œCaliforniaâ€).
4. **Solicitation #** â†’ from each scraperâ€™s `Code`.
5. **Due Date** â†’ formatted as string in PST (e.g., `2025-06-15 17:00:00 PST`).
6. **Keyword Hits** â†’ comma-separated matched keywords.
7. **Link** â†’ hyperlink to the solicitation page (or portal).

Conditional formatting:

* Alternating row colors per state (blue / yellow).
* Italic formatting for some date columns.
* Hyperlink style on â€œLinkâ€ column.
* Grey-out when checkbox is checked.
* Logo inserted at top left (`A1`).

*Sample screenshot:*
![Sample Excel Output](assets/output_example.png)

---

## ğŸ“¦ requirements.txt

```text
beautifulsoup4
pandas
selenium
Pillow
XlsxWriter
requests
pytz
lxml
```

---

## ğŸ¤ Contributing

This project is in early development. If you have ideasâ€”tests, new scrapers, bug fixesâ€”please open an issue or contact me via GitHub.

---

## ğŸ“„ License

Licensed under the MIT License. See `LICENSE` for full text.